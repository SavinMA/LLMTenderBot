import os
from documents_analyzer import DocumentsAnalyzer, AnalyzeResult
from config import MistralConfig
from ocr.mistral_ocr import MistralOCR
from prompts import Prompts
from queries import TenderData
from loguru import logger
import json
from mistralai import Mistral
from mistralai.models import File

class MistralAnalyzer(DocumentsAnalyzer):
    def __init__(self):
        super().__init__()
        self.llm_config = MistralConfig()

        self.model = self.llm_config.model
        self.client = Mistral(api_key=self.llm_config.api_key, timeout_ms=60000)
        self._check_api_key()

        self.ocr = MistralOCR()

    def _check_api_key(self) -> bool:
        """ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ñ API ĞºĞ»ÑÑ‡Ğ° Mistral."""
        if not self.llm_config.api_key:
            error_message = "âŒ API ĞºĞ»ÑÑ‡ Mistral Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½. Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚Ğµ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½ÑƒÑ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ MISTRAL_API_KEY."
            logger.error(error_message)
            raise Exception(error_message)
        logger.info("âœ… API ĞºĞ»ÑÑ‡ Mistral Ğ½Ğ°Ğ¹Ğ´ĞµĞ½.")
        return True

    def analyze(self, file_paths: list[str]) -> AnalyzeResult:
        file_errors = []
        summaries: list[TenderData] = []
        
        for file_path in file_paths:
            file_name = os.path.basename(file_path)
            try:
                summary: TenderData = self._analyze_file(file_path)
                summaries.append(summary)
            except Exception as e:
                file_errors.append(file_name)
        
        if file_errors:
            logger.error(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ¸ Ğ¿Ñ€Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞµ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²: {file_errors}")

        if summaries:
            global_summary = self._summarize_global(summaries)
        else:
            global_summary = None

        return AnalyzeResult(summary=global_summary, file_errors=file_errors)

    def _analyze_file(self, file_path: str) -> TenderData:
        """ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ° Ğ² Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¾Ñ‚ Ñ‚Ğ¸Ğ¿Ğ° Ñ„Ğ°Ğ¹Ğ»Ğ°"""
        file_extension = os.path.splitext(file_path)[1].lower()

        try:
            if file_extension in ['.docx', '.txt', '.pdf', '.doc']:
                return self._process_with_upload_file_and_chat(file_path)
            else:
                raise ValueError(f"ĞĞµĞ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµĞ¼Ñ‹Ğ¹ Ñ‚Ğ¸Ğ¿ Ñ„Ğ°Ğ¹Ğ»Ğ°: {file_extension}")
        except Exception as e:
            logger.error(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞµ Ñ„Ğ°Ğ¹Ğ»Ğ° {file_path}: {e}")
            raise e
        
    def _process_with_upload_file_and_chat(self, file_path: str) -> TenderData:
        """Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ñ„Ğ°Ğ¹Ğ»Ğ° Ğ² Mistral Ğ¸ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ° Ğ¾Ñ‚ Ñ‡Ğ°Ñ‚Ğ°"""
        logger.info(f"Processing with upload file and chat: {file_path}")
        file_id = None
        try:
            file_name = os.path.basename(file_path)

            with open(file_path, 'rb') as file:
                file_content = file.read()

            response = self.client.files.upload(
                file=File(
                    file_name=file_name,
                    content=file_content
                ),
                purpose="ocr"
            )
            file_id = response.id
            logger.debug(response)

            signed_url = self.client.files.get_signed_url(file_id=file_id)
            logger.debug(signed_url)

            messages = [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": "ĞÑ‚Ğ²ĞµÑ‚ÑŒ Ğ½Ğ° Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ¿Ğ¾ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ñƒ"
                        },
                        {
                            "type": "document_url",
                            "document_url": signed_url.url
                        }
                    ]
                }
            ]

            response = self.client.chat.parse(
                model=self.model,
                messages=messages,
                temperature=0.0,
                response_format=TenderData
            )
            logger.debug(response)
            return response.choices[0].message.parsed
        except Exception as e:
            logger.error(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ğ¸ Ğº Mistral API Ğ² _process_with_upload_file_and_chat: {e}")
            raise e
        finally:    
            if file_id:
                self.client.files.delete(file_id=file_id)

    def _summarize_global(self, summaries: list[TenderData]) -> str:
        logger.info("Starting global summarization.")

        # Parse and merge all TenderData objects
        if len(summaries) > 1:
            jsons = [tender_data.model_dump_json() for tender_data in summaries]
            summary_input_json = json.dumps(jsons)
        
            logger.debug(f"Summary input JSON: {summary_input_json}")
            # First LLM call for global summary
            logger.info("Calling LLM for global summary.")
            summary_result_prompt = Prompts.get_prompt_for_summarization(summary_input_json, "JSON")
            messages_global_summary = [
                {"role": "user", "content": summary_result_prompt}
            ]
            try:
                response_global_summary = self.client.chat.parse(
                    model=self.model,
                    messages=messages_global_summary,
                    temperature=0.0,
                    response_format=TenderData
                )
                global_summary_content = response_global_summary.choices[0].message.parsed
                logger.info("Global summary generated.")
                logger.debug(f"Global summary content: {global_summary_content}")
            except Exception as e:
                logger.error(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ğ¸ Ğº Mistral API Ğ¿Ñ€Ğ¸ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ³Ğ»Ğ¾Ğ±Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ ÑÑƒĞ¼Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ: {e}")
                return ""
        else:
            global_summary_content = summaries[0]

        telegram_markdown_content = self._create_telegram_message(global_summary_content)
        
        return telegram_markdown_content
    
    def _create_telegram_message(self, global_summary_content: TenderData) -> str:
        """Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Telegram ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ"""
        message_parts = []

        if global_summary_content.procurement_name:
            message_parts.append(f"ğŸ“¦ *ĞĞ°Ğ¸Ğ¼ĞµĞ½Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ·Ğ°ĞºÑƒĞ¿ĞºĞ¸*: {global_summary_content.procurement_name}")
        if global_summary_content.customer_info_company_name:
            message_parts.append(f"ğŸ¢ *Ğ—Ğ°ĞºĞ°Ğ·Ñ‡Ğ¸Ğº*: {global_summary_content.customer_info_company_name}")
        if global_summary_content.notice_number:
            message_parts.append(f"ğŸ“„ *ĞĞ¾Ğ¼ĞµÑ€ Ğ¸Ğ·Ğ²ĞµÑ‰ĞµĞ½Ğ¸Ñ*: {global_summary_content.notice_number}")
        if global_summary_content.publication_and_submission_deadline:
            message_parts.append(f"ğŸ—“ï¸ *Ğ¡Ñ€Ğ¾Ğº Ğ¿Ğ¾Ğ´Ğ°Ñ‡Ğ¸ Ğ·Ğ°ÑĞ²Ğ¾Ğº*: {global_summary_content.publication_and_submission_deadline}")
        if global_summary_content.lots:
            lots_info = []
            for i, lot in enumerate(global_summary_content.lots):
                lot_details = []
                if lot.name:
                    lot_details.append(f"ĞĞ°Ğ¸Ğ¼ĞµĞ½Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ: {lot.name}")
                if lot.initial_max_price:
                    lot_details.append(f"ĞĞ°Ñ‡Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ğ¼Ğ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ñ†ĞµĞ½Ğ°: {lot.initial_max_price}")
                if lot.currency:
                    lot_details.append(f"Ğ’Ğ°Ğ»ÑÑ‚Ğ°: {lot.currency}")
                if lot.quantity:
                    lot_details.append(f"ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾: {lot.quantity}")
                if lot_details:
                    lots_info.append(f"Ğ›Ğ¾Ñ‚ {i+1}:
  - " + "\n  - ".join(lot_details))
            if lots_info:
                message_parts.append(f"ğŸ·ï¸ *Ğ˜Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾ Ğ»Ğ¾Ñ‚Ğ°Ñ…*:
" + "\n".join(lots_info))
        if global_summary_content.delivery_department:
            message_parts.append(f"ğŸšš *ĞŸĞ¾Ğ´Ñ€Ğ°Ğ·Ğ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾ÑÑ‚Ğ°Ğ²ĞºĞ¸*: {global_summary_content.delivery_department}")
        if global_summary_content.initial_max_price_with_vat:
            message_parts.append(f"ğŸ’° *ĞĞ°Ñ‡Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ğ¼Ğ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ñ†ĞµĞ½Ğ° (Ñ ĞĞ”Ğ¡)*: {global_summary_content.initial_max_price_with_vat}")
        if global_summary_content.contact_persons:
            contact_persons_info = []
            for person in global_summary_content.contact_persons:
                person_details = []
                if person.full_name:
                    person_details.append(f"Ğ¤Ğ˜Ğ: {person.full_name}")
                if person.phone_number:
                    person_details.append(f"ğŸ“ Ğ¢ĞµĞ»ĞµÑ„Ğ¾Ğ½: {person.phone_number}")
                if person.email:
                    person_details.append(f"ğŸ“§ Email: {person.email}")
                if person.position:
                    person_details.append(f"ğŸ’¼ Ğ”Ğ¾Ğ»Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ: {person.position}")
                if person_details:
                    contact_persons_info.append("  - " + "\n    - ".join(person_details))
            if contact_persons_info:
                message_parts.append(f"ğŸ‘¤ *ĞšĞ¾Ğ½Ñ‚Ğ°ĞºÑ‚Ğ½Ñ‹Ğµ Ğ»Ğ¸Ñ†Ğ°*:
" + "\n".join(contact_persons_info))
        if global_summary_content.application_security:
            message_parts.append(f"ğŸ” *ĞĞ±ĞµÑĞ¿ĞµÑ‡ĞµĞ½Ğ¸Ğµ Ğ·Ğ°ÑĞ²ĞºĞ¸*: {global_summary_content.application_security}")
        if global_summary_content.re_bidding_date:
            message_parts.append(f"ğŸ”„ *Ğ”Ğ°Ñ‚Ğ° Ğ¿ĞµÑ€ĞµÑ‚Ğ¾Ñ€Ğ¶ĞºĞ¸*: {global_summary_content.re_bidding_date}")
        if global_summary_content.etp_platform:
            message_parts.append(f"ğŸŒ *Ğ­Ğ¢ĞŸ*: {global_summary_content.etp_platform}")
        if global_summary_content.application_review_deadline:
            message_parts.append(f"ğŸ“… *Ğ¡Ñ€Ğ¾Ğº Ñ€Ğ°ÑÑĞ¼Ğ¾Ñ‚Ñ€ĞµĞ½Ğ¸Ñ Ğ·Ğ°ÑĞ²Ğ¾Ğº*: {global_summary_content.application_review_deadline}")
        if global_summary_content.results_summary_date:
            message_parts.append(f"ğŸ“Š *Ğ”Ğ°Ñ‚Ğ° Ğ¿Ğ¾Ğ´Ğ²ĞµĞ´ĞµĞ½Ğ¸Ñ Ğ¸Ñ‚Ğ¾Ğ³Ğ¾Ğ²*: {global_summary_content.results_summary_date}")
        if global_summary_content.contract_security:
            message_parts.append(f"ğŸ“œ *ĞĞ±ĞµÑĞ¿ĞµÑ‡ĞµĞ½Ğ¸Ğµ Ğ´Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ°*: {global_summary_content.contract_security}")
        if global_summary_content.participation_price:
            message_parts.append(f"ğŸ’² *Ğ¦ĞµĞ½Ğ° ÑƒÑ‡Ğ°ÑÑ‚Ğ¸Ñ*: {global_summary_content.participation_price}")
        if global_summary_content.warranty_requirements:
            message_parts.append(f"ğŸ› ï¸ *Ğ“Ğ°Ñ€Ğ°Ğ½Ñ‚Ğ¸Ğ¹Ğ½Ñ‹Ğµ Ñ‚Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ*: {global_summary_content.warranty_requirements}")
        if global_summary_content.required_delivery_period:
            message_parts.append(f"â±ï¸ *Ğ¡Ñ€Ğ¾Ğº Ğ¿Ğ¾ÑÑ‚Ğ°Ğ²ĞºĞ¸*: {global_summary_content.required_delivery_period}")
        if global_summary_content.payment_terms:
            message_parts.append(f"ğŸ’³ *Ğ£ÑĞ»Ğ¾Ğ²Ğ¸Ñ Ğ¾Ğ¿Ğ»Ğ°Ñ‚Ñ‹*: {global_summary_content.payment_terms}")
        if global_summary_content.delivery_documents_names:
            message_parts.append(f"ğŸ“„ *Ğ”Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ñ‹ Ğ´Ğ»Ñ Ğ¿Ğ¾ÑÑ‚Ğ°Ğ²ĞºĞ¸*: {global_summary_content.delivery_documents_names}")
        if global_summary_content.delivery_method:
            message_parts.append(f"ğŸ“¦ *ĞœĞµÑ‚Ğ¾Ğ´ Ğ´Ğ¾ÑÑ‚Ğ°Ğ²ĞºĞ¸*: {global_summary_content.delivery_method}")
        if global_summary_content.product_dimensions:
            message_parts.append(f"ğŸ“ *Ğ Ğ°Ğ·Ğ¼ĞµÑ€Ñ‹ Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ°*: {global_summary_content.product_dimensions}")
        if global_summary_content.product_purpose:
            message_parts.append(f"ğŸ¯ *ĞĞ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ°*: {global_summary_content.product_purpose}")
        if global_summary_content.contract_term:
            message_parts.append(f"ğŸ—“ï¸ *Ğ¡Ñ€Ğ¾Ğº Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ Ğ´Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ°*: {global_summary_content.contract_term}")
        if global_summary_content.delivery_address:
            message_parts.append(f"ğŸ“ *ĞĞ´Ñ€ĞµÑ Ğ´Ğ¾ÑÑ‚Ğ°Ğ²ĞºĞ¸*: {global_summary_content.delivery_address}")
        
        telegram_markdown_content = "\n\n".join(message_parts)
        return telegram_markdown_content
        
        
        